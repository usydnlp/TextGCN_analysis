{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "final code.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fac181606ed74d8ba3e3958f047e1a75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6002cf0fda5544f0be515d31a00c5ae8",
              "IPY_MODEL_030498e3205c43d4a1e609cb1b1264fe"
            ],
            "layout": "IPY_MODEL_77ead1bf0bf140f5adf76d7527c9e178"
          },
          "model_module_version": "1.5.0"
        },
        "6002cf0fda5544f0be515d31a00c5ae8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "100%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fe228286c5e4a3db3302af980ead9da",
            "max": 18846,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a5e8afd311294b618247ebe379dca17c",
            "value": 18846
          },
          "model_module_version": "1.5.0"
        },
        "030498e3205c43d4a1e609cb1b1264fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd5a691254884d488544435a054da4fd",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_eded216c268b4aaeba575825fb70f131",
            "value": " 18846/18846 [05:34&lt;00:00, 56.34it/s]"
          },
          "model_module_version": "1.5.0"
        },
        "77ead1bf0bf140f5adf76d7527c9e178": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          },
          "model_module_version": "1.2.0"
        },
        "3fe228286c5e4a3db3302af980ead9da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          },
          "model_module_version": "1.2.0"
        },
        "a5e8afd311294b618247ebe379dca17c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          },
          "model_module_version": "1.5.0"
        },
        "dd5a691254884d488544435a054da4fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          },
          "model_module_version": "1.2.0"
        },
        "eded216c268b4aaeba575825fb70f131": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          },
          "model_module_version": "1.5.0"
        },
        "c51c527529cf4340be12d95d8c938329": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ebf926af032d4009ab03bee318dcd24c",
              "IPY_MODEL_3172a97132de4ce8820bde193addc5d4"
            ],
            "layout": "IPY_MODEL_7b3057700afd451fad175f4dcf650395"
          },
          "model_module_version": "1.5.0"
        },
        "ebf926af032d4009ab03bee318dcd24c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "100%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4273ec49f464c85a8406441f6228667",
            "max": 18846,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c40eaac787f34556bef98facfba6fbcd",
            "value": 18846
          },
          "model_module_version": "1.5.0"
        },
        "3172a97132de4ce8820bde193addc5d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16996a0f52a844758f4897d475599c35",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_6cf0128a4aca43e8a041a5a9d8b39cbe",
            "value": " 18846/18846 [1:35:17&lt;00:00,  3.30it/s]"
          },
          "model_module_version": "1.5.0"
        },
        "7b3057700afd451fad175f4dcf650395": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          },
          "model_module_version": "1.2.0"
        },
        "c4273ec49f464c85a8406441f6228667": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          },
          "model_module_version": "1.2.0"
        },
        "c40eaac787f34556bef98facfba6fbcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          },
          "model_module_version": "1.5.0"
        },
        "16996a0f52a844758f4897d475599c35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          },
          "model_module_version": "1.2.0"
        },
        "6cf0128a4aca43e8a041a5a9d8b39cbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          },
          "model_module_version": "1.5.0"
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6K9dWTv5I07_"
      },
      "source": [
        "# Hyper Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yn4zQ7DI4T0"
      },
      "source": [
        "EDGE = 2 # 0:d2w 1:d2w+w2w 2:d2w+w2w+d2d\n",
        "NODE = 0 # 0:one-hot #1:BERT \n",
        "NUM_LAYERS = 2 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJPI-IXrBkrP"
      },
      "source": [
        "# Dataset Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GyzNkI7W03D"
      },
      "source": [
        "original_train_sentences = \n",
        "original_labels_train = \n",
        "original_test_sentences = \n",
        "original_labels_test = \n",
        "\n",
        "train_size = len(original_train_sentences)\n",
        "test_size = len(original_test_sentences)\n",
        "sentences = original_train_sentences + original_test_sentences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2W7wKTBfa71"
      },
      "source": [
        "# Preprocess"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hobYcJ5OX5oT"
      },
      "source": [
        "## Label Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtWyhXiueMOq",
        "outputId": "c7c0f64f-9ce0-4d34-d0f9-1f2ac98e65b1"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "unique_labels=np.unique(original_labels_train)\n",
        "\n",
        "num_class = len(unique_labels)\n",
        "lEnc = LabelEncoder()\n",
        "lEnc.fit(unique_labels)\n",
        "\n",
        "print(unique_labels)\n",
        "print(lEnc.transform(unique_labels))\n",
        "\n",
        "train_labels = lEnc.transform(original_labels_train)\n",
        "test_labels = lEnc.transform(original_labels_test)\n",
        "\n",
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "labels = train_labels.tolist()+test_labels.tolist()\n",
        "labels = torch.LongTensor(labels).to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['alt.atheism' 'comp.graphics' 'comp.os.ms-windows.misc'\n",
            " 'comp.sys.ibm.pc.hardware' 'comp.sys.mac.hardware' 'comp.windows.x'\n",
            " 'misc.forsale' 'rec.autos' 'rec.motorcycles' 'rec.sport.baseball'\n",
            " 'rec.sport.hockey' 'sci.crypt' 'sci.electronics' 'sci.med' 'sci.space'\n",
            " 'soc.religion.christian' 'talk.politics.guns' 'talk.politics.mideast'\n",
            " 'talk.politics.misc' 'talk.religion.misc']\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMkEBxr6fMQi"
      },
      "source": [
        "## Remove Stopwords and less frequent words, tokenize sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xRG94uDfaBV",
        "outputId": "56567d39-3926-414a-ac14-6f6765826ac8"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import nltk\n",
        "import re\n",
        "\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "remove_limit = 5\n",
        "\n",
        "\n",
        "def clean_str(string):\n",
        "    string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string)\n",
        "    string = re.sub(r\"\\'s\", \" \\'s\", string)\n",
        "    string = re.sub(r\"\\'ve\", \" \\'ve\", string)\n",
        "    string = re.sub(r\"n\\'t\", \" n\\'t\", string)\n",
        "    string = re.sub(r\"\\'re\", \" \\'re\", string)\n",
        "    string = re.sub(r\"\\'d\", \" \\'d\", string)\n",
        "    string = re.sub(r\"\\'ll\", \" \\'ll\", string)\n",
        "    string = re.sub(r\",\", \" , \", string)\n",
        "    string = re.sub(r\"!\", \" ! \", string)\n",
        "    string = re.sub(r\"\\(\", \" \\( \", string)\n",
        "    string = re.sub(r\"\\)\", \" \\) \", string)\n",
        "    string = re.sub(r\"\\?\", \" \\? \", string)\n",
        "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
        "    return string.strip().lower()\n",
        "\n",
        "original_word_freq = {}  # to remove rare words\n",
        "for sentence in sentences:\n",
        "    temp = clean_str(sentence)\n",
        "    word_list = temp.split()\n",
        "    for word in word_list:\n",
        "        if word in original_word_freq:\n",
        "            original_word_freq[word] += 1\n",
        "        else:\n",
        "            original_word_freq[word] = 1   \n",
        "\n",
        "tokenize_sentences = []\n",
        "word_list_dict = {}\n",
        "for sentence in sentences:\n",
        "    temp = clean_str(sentence)\n",
        "    word_list_temp = temp.split()\n",
        "    doc_words = []\n",
        "    for word in word_list_temp: \n",
        "        if word in original_word_freq and word not in stop_words and original_word_freq[word] >= remove_limit:\n",
        "            doc_words.append(word)\n",
        "            word_list_dict[word] = 1\n",
        "    tokenize_sentences.append(doc_words)\n",
        "word_list = list(word_list_dict.keys())\n",
        "vocab_length = len(word_list)\n",
        "\n",
        "#word to id dict\n",
        "word_id_map = {}\n",
        "for i in range(vocab_length):\n",
        "    word_id_map[word_list[i]] = i            "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqLUncB2Pn_L"
      },
      "source": [
        "node_size = train_size + vocab_length + test_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0o8wcXgrTiD"
      },
      "source": [
        "# Model input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZbRV2wYxY1U"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from tqdm.notebook import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znJ7Grz7fQ2L"
      },
      "source": [
        "## Build Graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BSg1uNgV3_7"
      },
      "source": [
        "from math import log\n",
        "row = []\n",
        "col = []\n",
        "weight = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QESQPT88AqsI"
      },
      "source": [
        "### word-word: PMI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "fac181606ed74d8ba3e3958f047e1a75",
            "6002cf0fda5544f0be515d31a00c5ae8",
            "030498e3205c43d4a1e609cb1b1264fe",
            "77ead1bf0bf140f5adf76d7527c9e178",
            "3fe228286c5e4a3db3302af980ead9da",
            "a5e8afd311294b618247ebe379dca17c",
            "dd5a691254884d488544435a054da4fd",
            "eded216c268b4aaeba575825fb70f131"
          ]
        },
        "id": "KNlJoLFagXhv",
        "outputId": "857d32b8-16b4-40e7-db1f-47121c5ee39a"
      },
      "source": [
        "if EDGE >= 1:\n",
        "    window_size = 20\n",
        "    total_W = 0\n",
        "    word_occurrence = {}\n",
        "    word_pair_occurrence = {}\n",
        "\n",
        "    def ordered_word_pair(a, b):\n",
        "        if a > b:\n",
        "            return b, a\n",
        "        else:\n",
        "            return a, b\n",
        "\n",
        "    def update_word_and_word_pair_occurrence(q):\n",
        "        unique_q = list(set(q))\n",
        "        for i in unique_q:\n",
        "            try:\n",
        "                word_occurrence[i] += 1\n",
        "            except:\n",
        "                word_occurrence[i] = 1\n",
        "        for i in range(len(unique_q)):\n",
        "            for j in range(i+1, len(unique_q)):\n",
        "                word1 = unique_q[i]\n",
        "                word2 = unique_q[j]\n",
        "                word1, word2 = ordered_word_pair(word1, word2)\n",
        "                try:\n",
        "                    word_pair_occurrence[(word1, word2)] += 1\n",
        "                except:\n",
        "                    word_pair_occurrence[(word1, word2)] = 1\n",
        "\n",
        "\n",
        "    for ind in tqdm(range(train_size+test_size)):\n",
        "        words = tokenize_sentences[ind]\n",
        "\n",
        "        q = []\n",
        "        # push the first (window_size) words into a queue\n",
        "        for i in range(min(window_size, len(words))):\n",
        "            q += [word_id_map[words[i]]]\n",
        "        # update the total number of the sliding windows\n",
        "        total_W += 1\n",
        "        # update the number of sliding windows that contain each word and word pair\n",
        "        update_word_and_word_pair_occurrence(q)\n",
        "\n",
        "        now_next_word_index = window_size\n",
        "        # pop the first word out and let the next word in, keep doing this until the end of the document\n",
        "        while now_next_word_index<len(words):\n",
        "            q.pop(0)\n",
        "            q += [word_id_map[words[now_next_word_index]]]\n",
        "            now_next_word_index += 1\n",
        "            # update the total number of the sliding windows\n",
        "            total_W += 1\n",
        "            # update the number of sliding windows that contain each word and word pair\n",
        "            update_word_and_word_pair_occurrence(q)\n",
        "\n",
        "    for word_pair in word_pair_occurrence:\n",
        "        i = word_pair[0]\n",
        "        j = word_pair[1]\n",
        "        count = word_pair_occurrence[word_pair]\n",
        "        word_freq_i = word_occurrence[i]\n",
        "        word_freq_j = word_occurrence[j]\n",
        "        pmi = log((count * total_W) / (word_freq_i * word_freq_j))\n",
        "        if pmi <=0:\n",
        "            continue\n",
        "        row.append(train_size + i)\n",
        "        col.append(train_size + j)\n",
        "        weight.append(pmi)\n",
        "        row.append(train_size + j)\n",
        "        col.append(train_size + i)\n",
        "        weight.append(pmi)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fac181606ed74d8ba3e3958f047e1a75",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=18846.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hynLnT3a33kW"
      },
      "source": [
        "### doc-word: Tf-idf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnSPqhg1lHps"
      },
      "source": [
        "#get each word appears in which document\n",
        "word_doc_list = {}\n",
        "for word in word_list:\n",
        "    word_doc_list[word]=[]\n",
        "\n",
        "for i in range(len(tokenize_sentences)):\n",
        "    doc_words = tokenize_sentences[i]\n",
        "    unique_words = set(doc_words)\n",
        "    for word in unique_words:\n",
        "        exsit_list = word_doc_list[word]\n",
        "        exsit_list.append(i)\n",
        "        word_doc_list[word] = exsit_list\n",
        "\n",
        "#document frequency\n",
        "word_doc_freq = {}\n",
        "for word, doc_list in word_doc_list.items():\n",
        "    word_doc_freq[word] = len(doc_list)\n",
        "\n",
        "# term frequency\n",
        "doc_word_freq = {}\n",
        "\n",
        "for doc_id in range(len(tokenize_sentences)):\n",
        "    words = tokenize_sentences[doc_id]\n",
        "    for word in words:\n",
        "        word_id = word_id_map[word]\n",
        "        doc_word_str = str(doc_id) + ',' + str(word_id)\n",
        "        if doc_word_str in doc_word_freq:\n",
        "            doc_word_freq[doc_word_str] += 1\n",
        "        else:\n",
        "            doc_word_freq[doc_word_str] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6elPPFO_sXp"
      },
      "source": [
        "for i in range(len(tokenize_sentences)):\n",
        "    words = tokenize_sentences[i]\n",
        "    doc_word_set = set()\n",
        "    for word in words:\n",
        "        if word in doc_word_set:\n",
        "            continue\n",
        "        j = word_id_map[word]\n",
        "        key = str(i) + ',' + str(j)\n",
        "        freq = doc_word_freq[key]\n",
        "        if i < train_size:\n",
        "            row.append(i)\n",
        "        else:\n",
        "            row.append(i + vocab_length)\n",
        "        col.append(train_size + j)\n",
        "        idf = log(1.0 * len(tokenize_sentences) / word_doc_freq[word_list[j]])\n",
        "        weight.append(freq * idf)\n",
        "        doc_word_set.add(word)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAr6ygKhWTc-"
      },
      "source": [
        "### doc-doc: jaccard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "c51c527529cf4340be12d95d8c938329",
            "ebf926af032d4009ab03bee318dcd24c",
            "3172a97132de4ce8820bde193addc5d4",
            "7b3057700afd451fad175f4dcf650395",
            "c4273ec49f464c85a8406441f6228667",
            "c40eaac787f34556bef98facfba6fbcd",
            "16996a0f52a844758f4897d475599c35",
            "6cf0128a4aca43e8a041a5a9d8b39cbe"
          ]
        },
        "id": "T4-EH15oWWSX",
        "outputId": "96d42881-b803-4f71-e84f-5d358e0e3bc1"
      },
      "source": [
        "import nltk\n",
        "\n",
        "if EDGE>=2:\n",
        "    tokenize_sentences_set = [set(s) for s in tokenize_sentences]\n",
        "    jaccard_threshold = 0.2\n",
        "    for i in tqdm(range(len(tokenize_sentences))):\n",
        "        for j in range(i+1, len(tokenize_sentences)):\n",
        "            jaccard_w = 1 - nltk.jaccard_distance(tokenize_sentences_set[i], tokenize_sentences_set[j])\n",
        "            if jaccard_w > jaccard_threshold:\n",
        "                if i < train_size:\n",
        "                    row.append(i)\n",
        "                else:\n",
        "                    row.append(i + vocab_length)\n",
        "                if j < train_size:\n",
        "                    col.append(j)\n",
        "                else:\n",
        "                    col.append(vocab_length + j)\n",
        "                weight.append(jaccard_w)\n",
        "                if j < train_size:\n",
        "                    row.append(j)\n",
        "                else:\n",
        "                    row.append(j + vocab_length)\n",
        "                if i < train_size:\n",
        "                    col.append(i)\n",
        "                else:\n",
        "                    col.append(vocab_length + i)\n",
        "                weight.append(jaccard_w)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c51c527529cf4340be12d95d8c938329",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=18846.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIkGgB2aZDk7"
      },
      "source": [
        "### Adjacent matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0O1Ucdhod9a"
      },
      "source": [
        "import scipy.sparse as sp\n",
        "adj = sp.csr_matrix((weight, (row, col)), shape=(node_size, node_size))\n",
        "\n",
        "# build symmetric adjacency matrix\n",
        "adj = adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivyuexATkQFW"
      },
      "source": [
        "def normalize_adj(adj):\n",
        "    \"\"\"Symmetrically normalize adjacency matrix.\"\"\"\n",
        "    adj = sp.coo_matrix(adj)\n",
        "    rowsum = np.array(adj.sum(1))\n",
        "    d_inv_sqrt = np.power(rowsum, -0.5).flatten()\n",
        "    d_inv_sqrt[np.isinf(d_inv_sqrt)] = 0.\n",
        "    d_mat_inv_sqrt = sp.diags(d_inv_sqrt)\n",
        "    return adj.dot(d_mat_inv_sqrt).transpose().dot(d_mat_inv_sqrt).tocoo(), d_inv_sqrt\n",
        "    \n",
        "adj, norm_item = normalize_adj(adj + sp.eye(adj.shape[0]))\n",
        "\n",
        "\n",
        "def sparse_mx_to_torch_sparse_tensor(sparse_mx):\n",
        "    \"\"\"Convert a scipy sparse matrix to a torch sparse tensor.\"\"\"\n",
        "    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n",
        "    indices = torch.from_numpy(\n",
        "        np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))\n",
        "    values = torch.from_numpy(sparse_mx.data)\n",
        "    shape = torch.Size(sparse_mx.shape)\n",
        "    return torch.sparse.FloatTensor(indices, values, shape).to(device)\n",
        "\n",
        "adj = sparse_mx_to_torch_sparse_tensor(adj)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMgbhTstMSUA"
      },
      "source": [
        "## Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mP9dqCskOrXT"
      },
      "source": [
        "if NODE == 0:\n",
        "    features = np.arange(node_size)\n",
        "    features = torch.FloatTensor(features).to(device)\n",
        "else:\n",
        "    !pip install flair\n",
        "\n",
        "    from flair.embeddings import TransformerDocumentEmbeddings, TransformerWordEmbeddings\n",
        "    from flair.data import Sentence\n",
        "    doc_embedding = TransformerDocumentEmbeddings('bert-base-uncased', fine_tune=False)\n",
        "    word_embedding = TransformerWordEmbeddings('bert-base-uncased', layers='-1',subtoken_pooling=\"mean\")\n",
        "\n",
        "    sent_embs = []\n",
        "    word_embs = {}\n",
        "\n",
        "    for ind in tqdm(range(train_size+test_size)):\n",
        "        sent = tokenize_sentences[ind]\n",
        "        sentence = Sentence(\" \".join(sent[:512]),use_tokenizer=False)\n",
        "        doc_embedding.embed(sentence)\n",
        "        sent_embs.append(sentence.get_embedding().tolist())\n",
        "        words = Sentence(\" \".join(sent[:512]),use_tokenizer=False)\n",
        "        word_embedding.embed(words)\n",
        "        for token in words:\n",
        "            word = token.text\n",
        "            embedding = token.embedding.tolist()\n",
        "            if word not in word_embs:\n",
        "                word_embs[word] = embedding\n",
        "            else:\n",
        "                word_embs[word] = np.minimum(word_embs[word], embedding)\n",
        "\n",
        "    word_embs_list = []\n",
        "    for word in word_list:\n",
        "        word_embs_list.append(word_embs[word])\n",
        "\n",
        "    features = sent_embs[:train_size] + word_embs_list + sent_embs[train_size:]\n",
        "\n",
        "    import scipy.sparse as sp\n",
        "    def preprocess_features(features):\n",
        "        \"\"\"Row-normalize feature matrix and convert to tuple representation\"\"\"\n",
        "        rowsum = np.array(features.sum(1))\n",
        "        r_inv = np.power(rowsum, -1).flatten()\n",
        "        r_inv[np.isinf(r_inv)] = 0.\n",
        "        r_mat_inv = sp.diags(r_inv)\n",
        "        features = r_mat_inv.dot(features)\n",
        "        return features\n",
        "\n",
        "    features = preprocess_features(sp.csr_matrix(features)).todense()\n",
        "    features = torch.FloatTensor(features).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdx6RrUvjbF0"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39Kj8NQujiDH"
      },
      "source": [
        "## GCN Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNVkA-h7b3sP"
      },
      "source": [
        "import math\n",
        "\n",
        "import torch\n",
        "\n",
        "from torch.nn.parameter import Parameter\n",
        "from torch.nn.modules.module import Module\n",
        "\n",
        "\n",
        "class GraphConvolution(Module):\n",
        "    \"\"\"\n",
        "    Simple GCN layer, similar to https://arxiv.org/abs/1609.02907\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_features, out_features,  drop_out = 0, activation=None, bias=True):\n",
        "        super(GraphConvolution, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.weight = Parameter(torch.FloatTensor(in_features, out_features))\n",
        "        if bias:\n",
        "            self.bias = Parameter(torch.zeros(1, out_features))\n",
        "        else:\n",
        "            self.register_parameter('bias', None)\n",
        "        self.reset_parameters(in_features, out_features)\n",
        "        self.dropout = torch.nn.Dropout(drop_out)\n",
        "        self.activation =  activation\n",
        "\n",
        "    def reset_parameters(self,in_features, out_features):\n",
        "        stdv = np.sqrt(6.0/(in_features+out_features))\n",
        "        # stdv = 1. / math.sqrt(self.weight.size(1))\n",
        "        self.weight.data.uniform_(-stdv, stdv)\n",
        "        # if self.bias is not None:\n",
        "        #     torch.nn.init.zeros_(self.bias)\n",
        "            # self.bias.data.uniform_(-stdv, stdv)\n",
        "\n",
        "\n",
        "    def forward(self, input, adj, feature_less = False):\n",
        "        if feature_less:\n",
        "            support = self.weight\n",
        "            support = self.dropout(support)\n",
        "        else:\n",
        "            input = self.dropout(input)\n",
        "            support = torch.mm(input, self.weight)\n",
        "        output = torch.spmm(adj, support)\n",
        "        if self.bias is not None:\n",
        "            output = output + self.bias\n",
        "        if self.activation is not None:\n",
        "            output = self.activation(output)\n",
        "        return output\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + ' (' \\\n",
        "               + str(self.in_features) + ' -> ' \\\n",
        "               + str(self.out_features) + ')'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k57M4sz4s4Md"
      },
      "source": [
        "## GCN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJ-ZQuMzs5tZ"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class GCN(nn.Module):\n",
        "    def __init__(self, nfeat, nhid, nclass, dropout, n_layers = 2):\n",
        "        super(GCN, self).__init__()\n",
        "        self.n_layers = n_layers\n",
        "        self.gc_list = []\n",
        "        if n_layers >= 2:\n",
        "            self.gc1 = GraphConvolution(nfeat, nhid, dropout, activation = nn.ReLU())\n",
        "            self.gc_list = nn.ModuleList([GraphConvolution(nhid, nhid, dropout, activation = nn.ReLU()) for _ in range(self.n_layers-2)])\n",
        "            self.gcf = GraphConvolution(nhid, nclass, dropout)\n",
        "        else:\n",
        "            self.gc1 = GraphConvolution(nfeat, nclass, dropout)\n",
        "\n",
        "    def forward(self, x, adj):\n",
        "        if self.n_layers>=2:\n",
        "            x = self.gc1(x, adj, feature_less = True)\n",
        "            for i in range(self.n_layers-2):\n",
        "                x = self.gc_list[i](x,adj)\n",
        "            x = self.gcf(x,adj)\n",
        "        else:\n",
        "            x = self.gc1(x, adj, feature_less = True)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmhOG1yG--Ji"
      },
      "source": [
        "def cal_accuracy(predictions,labels):\n",
        "    pred = torch.argmax(predictions,-1).cpu().tolist()\n",
        "    lab = labels.cpu().tolist()\n",
        "    cor = 0\n",
        "    for i in range(len(pred)):\n",
        "        if pred[i] == lab[i]:\n",
        "            cor += 1\n",
        "    return cor/len(pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEE4JxeUthCb"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIxII4QoticA"
      },
      "source": [
        "## Initialize model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdNsgxMG-Wwu"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "HIDDEN_DIM = 200\n",
        "DROP_OUT = 0.5\n",
        "LR = 0.02\n",
        "WEIGHT_DECAY = 0\n",
        "EARLY_STOPPING = 10\n",
        "NUM_EPOCHS = 200\n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "model = GCN(nfeat=node_size, nhid=HIDDEN_DIM, nclass=num_class, dropout=DROP_OUT,n_layers=NUM_LAYERS).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T98r4qZuuFyn"
      },
      "source": [
        "## Training and Validating"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bv9br9pgGw9R"
      },
      "source": [
        "def generate_train_val(train_pro=0.9):\n",
        "    real_train_size = int(train_pro*train_size)\n",
        "    val_size = train_size-real_train_size\n",
        "\n",
        "    idx_train = np.random.choice(train_size, real_train_size,replace=False)\n",
        "    idx_train.sort()\n",
        "    idx_val = []\n",
        "    pointer = 0\n",
        "    for v in range(train_size):\n",
        "        if pointer<len(idx_train) and idx_train[pointer] == v:\n",
        "            pointer +=1\n",
        "        else:\n",
        "            idx_val.append(v)\n",
        "    idx_test = range(train_size+vocab_length, node_size)\n",
        "    return idx_train, idx_val, idx_test\n",
        "\n",
        "idx_train, idx_val, idx_test = generate_train_val()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QC7u3Jn2uIu4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d446816-2517-4e4b-cb8d-b38d5dc2ae93"
      },
      "source": [
        "import time\n",
        "\n",
        "def train_model(show_result = True):\n",
        "    val_loss = []\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        t = time.time()\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        output= model(features, adj)\n",
        "        loss_train = criterion(output[idx_train], labels[idx_train])\n",
        "        acc_train = cal_accuracy(output[idx_train], labels[idx_train])\n",
        "        loss_train.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        model.eval()\n",
        "        output = model(features, adj)\n",
        "\n",
        "        loss_val = criterion(output[idx_val], labels[idx_val])\n",
        "        val_loss.append(loss_val.item())\n",
        "        acc_val = cal_accuracy(output[idx_val], labels[idx_val])\n",
        "        if show_result:\n",
        "            print(  'Epoch: {:04d}'.format(epoch+1),\n",
        "                    'loss_train: {:.4f}'.format(loss_train.item()),\n",
        "                    'acc_train: {:.4f}'.format(acc_train),\n",
        "                    'loss_val: {:.4f}'.format(loss_val.item()),\n",
        "                    'acc_val: {:.4f}'.format(acc_val),\n",
        "                    'time: {:.4f}s'.format(time.time() - t))\n",
        "        \n",
        "        if epoch > EARLY_STOPPING and np.min(val_loss[-EARLY_STOPPING:]) > np.min(val_loss[:-EARLY_STOPPING]) :\n",
        "            if show_result:\n",
        "                print(\"Early Stopping...\")\n",
        "            break\n",
        "\n",
        "train_model()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0001 loss_train: 2.9957 acc_train: 0.0433 loss_val: 2.9918 acc_val: 0.0486 time: 0.8628s\n",
            "Epoch: 0002 loss_train: 2.9898 acc_train: 0.0544 loss_val: 3.0036 acc_val: 0.0574 time: 0.8527s\n",
            "Epoch: 0003 loss_train: 2.9891 acc_train: 0.0630 loss_val: 2.9875 acc_val: 0.0530 time: 0.8524s\n",
            "Epoch: 0004 loss_train: 2.9820 acc_train: 0.0583 loss_val: 2.9810 acc_val: 0.0813 time: 0.8523s\n",
            "Epoch: 0005 loss_train: 2.9776 acc_train: 0.0968 loss_val: 2.9727 acc_val: 0.1042 time: 0.8525s\n",
            "Epoch: 0006 loss_train: 2.9683 acc_train: 0.1246 loss_val: 2.9600 acc_val: 0.0707 time: 0.8521s\n",
            "Epoch: 0007 loss_train: 2.9538 acc_train: 0.0788 loss_val: 2.9439 acc_val: 0.1051 time: 0.8531s\n",
            "Epoch: 0008 loss_train: 2.9339 acc_train: 0.1110 loss_val: 2.9186 acc_val: 0.1387 time: 0.8525s\n",
            "Epoch: 0009 loss_train: 2.9060 acc_train: 0.1395 loss_val: 2.8799 acc_val: 0.1263 time: 0.8520s\n",
            "Epoch: 0010 loss_train: 2.8639 acc_train: 0.1370 loss_val: 2.8235 acc_val: 0.2217 time: 0.8523s\n",
            "Epoch: 0011 loss_train: 2.8060 acc_train: 0.2352 loss_val: 2.7519 acc_val: 0.2191 time: 0.8528s\n",
            "Epoch: 0012 loss_train: 2.7266 acc_train: 0.2307 loss_val: 2.6618 acc_val: 0.2491 time: 0.8528s\n",
            "Epoch: 0013 loss_train: 2.6334 acc_train: 0.2495 loss_val: 2.5822 acc_val: 0.2898 time: 0.8537s\n",
            "Epoch: 0014 loss_train: 2.5429 acc_train: 0.2940 loss_val: 2.6899 acc_val: 0.1634 time: 0.8530s\n",
            "Epoch: 0015 loss_train: 2.6562 acc_train: 0.1684 loss_val: 2.4454 acc_val: 0.3269 time: 0.8530s\n",
            "Epoch: 0016 loss_train: 2.4098 acc_train: 0.3307 loss_val: 2.5689 acc_val: 0.1723 time: 0.8519s\n",
            "Epoch: 0017 loss_train: 2.5350 acc_train: 0.1893 loss_val: 2.3402 acc_val: 0.4037 time: 0.8529s\n",
            "Epoch: 0018 loss_train: 2.3181 acc_train: 0.3663 loss_val: 2.4150 acc_val: 0.2253 time: 0.8521s\n",
            "Epoch: 0019 loss_train: 2.3879 acc_train: 0.2388 loss_val: 2.3175 acc_val: 0.2341 time: 0.8529s\n",
            "Epoch: 0020 loss_train: 2.2800 acc_train: 0.2602 loss_val: 2.2595 acc_val: 0.3887 time: 0.8521s\n",
            "Epoch: 0021 loss_train: 2.2020 acc_train: 0.3877 loss_val: 2.3043 acc_val: 0.3198 time: 0.8532s\n",
            "Epoch: 0022 loss_train: 2.2394 acc_train: 0.3172 loss_val: 2.1707 acc_val: 0.4072 time: 0.8517s\n",
            "Epoch: 0023 loss_train: 2.1058 acc_train: 0.4258 loss_val: 2.1994 acc_val: 0.3136 time: 0.8528s\n",
            "Epoch: 0024 loss_train: 2.1397 acc_train: 0.3288 loss_val: 2.1173 acc_val: 0.3754 time: 0.8522s\n",
            "Epoch: 0025 loss_train: 2.0562 acc_train: 0.3943 loss_val: 2.0612 acc_val: 0.4417 time: 0.8520s\n",
            "Epoch: 0026 loss_train: 2.0057 acc_train: 0.4230 loss_val: 2.0638 acc_val: 0.4223 time: 0.8527s\n",
            "Epoch: 0027 loss_train: 2.0001 acc_train: 0.4133 loss_val: 1.9651 acc_val: 0.4373 time: 0.8532s\n",
            "Epoch: 0028 loss_train: 1.9020 acc_train: 0.4574 loss_val: 1.9727 acc_val: 0.4108 time: 0.8527s\n",
            "Epoch: 0029 loss_train: 1.9240 acc_train: 0.4257 loss_val: 1.9014 acc_val: 0.4585 time: 0.8525s\n",
            "Epoch: 0030 loss_train: 1.8355 acc_train: 0.4596 loss_val: 1.8935 acc_val: 0.4894 time: 0.8522s\n",
            "Epoch: 0031 loss_train: 1.8202 acc_train: 0.4719 loss_val: 1.8596 acc_val: 0.4770 time: 0.8527s\n",
            "Epoch: 0032 loss_train: 1.7790 acc_train: 0.4629 loss_val: 1.8107 acc_val: 0.4938 time: 0.8526s\n",
            "Epoch: 0033 loss_train: 1.7370 acc_train: 0.4874 loss_val: 1.7792 acc_val: 0.4947 time: 0.8529s\n",
            "Epoch: 0034 loss_train: 1.7041 acc_train: 0.4751 loss_val: 1.7351 acc_val: 0.5115 time: 0.8516s\n",
            "Epoch: 0035 loss_train: 1.6557 acc_train: 0.4978 loss_val: 1.7331 acc_val: 0.4850 time: 0.8530s\n",
            "Epoch: 0036 loss_train: 1.6472 acc_train: 0.4800 loss_val: 1.6792 acc_val: 0.5035 time: 0.8518s\n",
            "Epoch: 0037 loss_train: 1.6083 acc_train: 0.5006 loss_val: 1.6881 acc_val: 0.4956 time: 0.8519s\n",
            "Epoch: 0038 loss_train: 1.6229 acc_train: 0.4683 loss_val: 1.6351 acc_val: 0.4912 time: 0.8514s\n",
            "Epoch: 0039 loss_train: 1.5405 acc_train: 0.5099 loss_val: 1.6228 acc_val: 0.5124 time: 0.8530s\n",
            "Epoch: 0040 loss_train: 1.5296 acc_train: 0.5021 loss_val: 1.5713 acc_val: 0.5292 time: 0.8521s\n",
            "Epoch: 0041 loss_train: 1.4876 acc_train: 0.5270 loss_val: 1.5855 acc_val: 0.5062 time: 0.8528s\n",
            "Epoch: 0042 loss_train: 1.5071 acc_train: 0.4924 loss_val: 1.5003 acc_val: 0.5618 time: 0.8524s\n",
            "Epoch: 0043 loss_train: 1.4184 acc_train: 0.5567 loss_val: 1.4989 acc_val: 0.5557 time: 0.8529s\n",
            "Epoch: 0044 loss_train: 1.4166 acc_train: 0.5509 loss_val: 1.4811 acc_val: 0.5327 time: 0.8517s\n",
            "Epoch: 0045 loss_train: 1.3844 acc_train: 0.5326 loss_val: 1.4633 acc_val: 0.5539 time: 0.8531s\n",
            "Epoch: 0046 loss_train: 1.3799 acc_train: 0.5443 loss_val: 1.4370 acc_val: 0.5442 time: 0.8515s\n",
            "Epoch: 0047 loss_train: 1.3428 acc_train: 0.5545 loss_val: 1.3908 acc_val: 0.5769 time: 0.8532s\n",
            "Epoch: 0048 loss_train: 1.3051 acc_train: 0.5904 loss_val: 1.3874 acc_val: 0.5751 time: 0.8521s\n",
            "Epoch: 0049 loss_train: 1.2976 acc_train: 0.5745 loss_val: 1.3918 acc_val: 0.5380 time: 0.8531s\n",
            "Epoch: 0050 loss_train: 1.3012 acc_train: 0.5474 loss_val: 1.3514 acc_val: 0.5751 time: 0.8525s\n",
            "Epoch: 0051 loss_train: 1.2896 acc_train: 0.5685 loss_val: 1.3044 acc_val: 0.6069 time: 0.8528s\n",
            "Epoch: 0052 loss_train: 1.2165 acc_train: 0.6006 loss_val: 1.3202 acc_val: 0.5707 time: 0.8524s\n",
            "Epoch: 0053 loss_train: 1.2190 acc_train: 0.5845 loss_val: 1.2882 acc_val: 0.5981 time: 0.8530s\n",
            "Epoch: 0054 loss_train: 1.1918 acc_train: 0.6049 loss_val: 1.2432 acc_val: 0.6104 time: 0.8522s\n",
            "Epoch: 0055 loss_train: 1.1667 acc_train: 0.6155 loss_val: 1.3008 acc_val: 0.5733 time: 0.8532s\n",
            "Epoch: 0056 loss_train: 1.2093 acc_train: 0.5766 loss_val: 1.2693 acc_val: 0.5848 time: 0.8513s\n",
            "Epoch: 0057 loss_train: 1.1934 acc_train: 0.5878 loss_val: 1.2089 acc_val: 0.6122 time: 0.8532s\n",
            "Epoch: 0058 loss_train: 1.1393 acc_train: 0.6095 loss_val: 1.2236 acc_val: 0.5875 time: 0.8516s\n",
            "Epoch: 0059 loss_train: 1.1372 acc_train: 0.6041 loss_val: 1.2165 acc_val: 0.5963 time: 0.8522s\n",
            "Epoch: 0060 loss_train: 1.1302 acc_train: 0.6083 loss_val: 1.1503 acc_val: 0.6210 time: 0.8529s\n",
            "Epoch: 0061 loss_train: 1.0742 acc_train: 0.6374 loss_val: 1.1669 acc_val: 0.6325 time: 0.8525s\n",
            "Epoch: 0062 loss_train: 1.0959 acc_train: 0.6243 loss_val: 1.0973 acc_val: 0.6705 time: 0.8533s\n",
            "Epoch: 0063 loss_train: 1.0296 acc_train: 0.6612 loss_val: 1.1264 acc_val: 0.6316 time: 0.8535s\n",
            "Epoch: 0064 loss_train: 1.0629 acc_train: 0.6426 loss_val: 1.1270 acc_val: 0.6175 time: 0.8529s\n",
            "Epoch: 0065 loss_train: 1.0451 acc_train: 0.6320 loss_val: 1.0845 acc_val: 0.6405 time: 0.8533s\n",
            "Epoch: 0066 loss_train: 1.0075 acc_train: 0.6588 loss_val: 1.0885 acc_val: 0.6422 time: 0.8533s\n",
            "Epoch: 0067 loss_train: 1.0105 acc_train: 0.6496 loss_val: 1.0661 acc_val: 0.6731 time: 0.8524s\n",
            "Epoch: 0068 loss_train: 0.9866 acc_train: 0.6656 loss_val: 1.0375 acc_val: 0.6802 time: 0.8536s\n",
            "Epoch: 0069 loss_train: 0.9569 acc_train: 0.6832 loss_val: 1.0576 acc_val: 0.6696 time: 0.8537s\n",
            "Epoch: 0070 loss_train: 0.9596 acc_train: 0.6826 loss_val: 1.0279 acc_val: 0.6705 time: 0.8526s\n",
            "Epoch: 0071 loss_train: 0.9347 acc_train: 0.6896 loss_val: 1.0132 acc_val: 0.6802 time: 0.8535s\n",
            "Epoch: 0072 loss_train: 0.9362 acc_train: 0.6724 loss_val: 0.9887 acc_val: 0.6890 time: 0.8530s\n",
            "Epoch: 0073 loss_train: 0.9146 acc_train: 0.6809 loss_val: 0.9834 acc_val: 0.6917 time: 0.8535s\n",
            "Epoch: 0074 loss_train: 0.9043 acc_train: 0.7039 loss_val: 0.9990 acc_val: 0.6723 time: 0.8523s\n",
            "Epoch: 0075 loss_train: 0.9040 acc_train: 0.6993 loss_val: 0.9684 acc_val: 0.7076 time: 0.8534s\n",
            "Epoch: 0076 loss_train: 0.8725 acc_train: 0.7198 loss_val: 0.9498 acc_val: 0.7129 time: 0.8523s\n",
            "Epoch: 0077 loss_train: 0.8692 acc_train: 0.7131 loss_val: 0.9302 acc_val: 0.7182 time: 0.8534s\n",
            "Epoch: 0078 loss_train: 0.8522 acc_train: 0.7233 loss_val: 0.9318 acc_val: 0.7208 time: 0.8541s\n",
            "Epoch: 0079 loss_train: 0.8435 acc_train: 0.7280 loss_val: 0.9350 acc_val: 0.7102 time: 0.8534s\n",
            "Epoch: 0080 loss_train: 0.8422 acc_train: 0.7209 loss_val: 0.9012 acc_val: 0.7270 time: 0.8533s\n",
            "Epoch: 0081 loss_train: 0.8156 acc_train: 0.7276 loss_val: 0.8909 acc_val: 0.7420 time: 0.8530s\n",
            "Epoch: 0082 loss_train: 0.8058 acc_train: 0.7362 loss_val: 0.8925 acc_val: 0.7297 time: 0.8529s\n",
            "Epoch: 0083 loss_train: 0.7988 acc_train: 0.7388 loss_val: 0.8751 acc_val: 0.7164 time: 0.8536s\n",
            "Epoch: 0084 loss_train: 0.7910 acc_train: 0.7319 loss_val: 0.8698 acc_val: 0.7376 time: 0.8531s\n",
            "Epoch: 0085 loss_train: 0.7743 acc_train: 0.7515 loss_val: 0.8483 acc_val: 0.7447 time: 0.8544s\n",
            "Epoch: 0086 loss_train: 0.7587 acc_train: 0.7546 loss_val: 0.8394 acc_val: 0.7615 time: 0.8527s\n",
            "Epoch: 0087 loss_train: 0.7700 acc_train: 0.7537 loss_val: 0.8484 acc_val: 0.7544 time: 0.8536s\n",
            "Epoch: 0088 loss_train: 0.7556 acc_train: 0.7598 loss_val: 0.8335 acc_val: 0.7226 time: 0.8535s\n",
            "Epoch: 0089 loss_train: 0.7456 acc_train: 0.7502 loss_val: 0.8424 acc_val: 0.7509 time: 0.8531s\n",
            "Epoch: 0090 loss_train: 0.7460 acc_train: 0.7637 loss_val: 0.8265 acc_val: 0.7456 time: 0.8530s\n",
            "Epoch: 0091 loss_train: 0.7323 acc_train: 0.7591 loss_val: 0.8000 acc_val: 0.7518 time: 0.8530s\n",
            "Epoch: 0092 loss_train: 0.7130 acc_train: 0.7654 loss_val: 0.8214 acc_val: 0.7473 time: 0.8531s\n",
            "Epoch: 0093 loss_train: 0.7255 acc_train: 0.7635 loss_val: 0.8151 acc_val: 0.7447 time: 0.8537s\n",
            "Epoch: 0094 loss_train: 0.7133 acc_train: 0.7701 loss_val: 0.8077 acc_val: 0.7571 time: 0.8532s\n",
            "Epoch: 0095 loss_train: 0.7037 acc_train: 0.7761 loss_val: 0.7949 acc_val: 0.7668 time: 0.8537s\n",
            "Epoch: 0096 loss_train: 0.7053 acc_train: 0.7806 loss_val: 0.8052 acc_val: 0.7429 time: 0.8533s\n",
            "Epoch: 0097 loss_train: 0.7144 acc_train: 0.7609 loss_val: 0.8014 acc_val: 0.7792 time: 0.8547s\n",
            "Epoch: 0098 loss_train: 0.6969 acc_train: 0.7736 loss_val: 0.7790 acc_val: 0.7739 time: 0.8528s\n",
            "Epoch: 0099 loss_train: 0.6640 acc_train: 0.7884 loss_val: 0.7769 acc_val: 0.7686 time: 0.8538s\n",
            "Epoch: 0100 loss_train: 0.6823 acc_train: 0.7766 loss_val: 0.7842 acc_val: 0.7580 time: 0.8536s\n",
            "Epoch: 0101 loss_train: 0.6801 acc_train: 0.7760 loss_val: 0.7710 acc_val: 0.7862 time: 0.8525s\n",
            "Epoch: 0102 loss_train: 0.6493 acc_train: 0.7995 loss_val: 0.7917 acc_val: 0.7686 time: 0.8524s\n",
            "Epoch: 0103 loss_train: 0.6658 acc_train: 0.7894 loss_val: 0.7512 acc_val: 0.7862 time: 0.8540s\n",
            "Epoch: 0104 loss_train: 0.6398 acc_train: 0.8003 loss_val: 0.7275 acc_val: 0.8012 time: 0.8525s\n",
            "Epoch: 0105 loss_train: 0.6308 acc_train: 0.8020 loss_val: 0.7599 acc_val: 0.7809 time: 0.8532s\n",
            "Epoch: 0106 loss_train: 0.6461 acc_train: 0.7976 loss_val: 0.7336 acc_val: 0.7986 time: 0.8525s\n",
            "Epoch: 0107 loss_train: 0.6156 acc_train: 0.8149 loss_val: 0.7306 acc_val: 0.7889 time: 0.8532s\n",
            "Epoch: 0108 loss_train: 0.6105 acc_train: 0.8113 loss_val: 0.7391 acc_val: 0.7924 time: 0.8527s\n",
            "Epoch: 0109 loss_train: 0.6281 acc_train: 0.8010 loss_val: 0.7072 acc_val: 0.8030 time: 0.8531s\n",
            "Epoch: 0110 loss_train: 0.5978 acc_train: 0.8121 loss_val: 0.7223 acc_val: 0.8039 time: 0.8527s\n",
            "Epoch: 0111 loss_train: 0.6110 acc_train: 0.8086 loss_val: 0.7364 acc_val: 0.7871 time: 0.8514s\n",
            "Epoch: 0112 loss_train: 0.5949 acc_train: 0.8135 loss_val: 0.6909 acc_val: 0.8012 time: 0.8519s\n",
            "Epoch: 0113 loss_train: 0.5751 acc_train: 0.8233 loss_val: 0.7033 acc_val: 0.8065 time: 0.8534s\n",
            "Epoch: 0114 loss_train: 0.5807 acc_train: 0.8232 loss_val: 0.6970 acc_val: 0.8074 time: 0.8523s\n",
            "Epoch: 0115 loss_train: 0.5621 acc_train: 0.8342 loss_val: 0.7110 acc_val: 0.7898 time: 0.8528s\n",
            "Epoch: 0116 loss_train: 0.5762 acc_train: 0.8140 loss_val: 0.6869 acc_val: 0.7995 time: 0.8527s\n",
            "Epoch: 0117 loss_train: 0.5626 acc_train: 0.8266 loss_val: 0.6800 acc_val: 0.8092 time: 0.8532s\n",
            "Epoch: 0118 loss_train: 0.5672 acc_train: 0.8300 loss_val: 0.7027 acc_val: 0.7906 time: 0.8528s\n",
            "Epoch: 0119 loss_train: 0.5627 acc_train: 0.8183 loss_val: 0.6784 acc_val: 0.8136 time: 0.8530s\n",
            "Epoch: 0120 loss_train: 0.5461 acc_train: 0.8320 loss_val: 0.6827 acc_val: 0.8030 time: 0.8524s\n",
            "Epoch: 0121 loss_train: 0.5659 acc_train: 0.8270 loss_val: 0.6893 acc_val: 0.7995 time: 0.8528s\n",
            "Epoch: 0122 loss_train: 0.5569 acc_train: 0.8247 loss_val: 0.6552 acc_val: 0.8189 time: 0.8525s\n",
            "Epoch: 0123 loss_train: 0.5201 acc_train: 0.8392 loss_val: 0.6458 acc_val: 0.8295 time: 0.8525s\n",
            "Epoch: 0124 loss_train: 0.5185 acc_train: 0.8432 loss_val: 0.6616 acc_val: 0.8110 time: 0.8521s\n",
            "Epoch: 0125 loss_train: 0.5212 acc_train: 0.8457 loss_val: 0.6516 acc_val: 0.8039 time: 0.8532s\n",
            "Epoch: 0126 loss_train: 0.5206 acc_train: 0.8380 loss_val: 0.6298 acc_val: 0.8251 time: 0.8526s\n",
            "Epoch: 0127 loss_train: 0.4994 acc_train: 0.8481 loss_val: 0.6489 acc_val: 0.8269 time: 0.8529s\n",
            "Epoch: 0128 loss_train: 0.5054 acc_train: 0.8517 loss_val: 0.6333 acc_val: 0.8207 time: 0.8525s\n",
            "Epoch: 0129 loss_train: 0.5037 acc_train: 0.8444 loss_val: 0.6071 acc_val: 0.8295 time: 0.8535s\n",
            "Epoch: 0130 loss_train: 0.4807 acc_train: 0.8590 loss_val: 0.6051 acc_val: 0.8313 time: 0.8517s\n",
            "Epoch: 0131 loss_train: 0.4855 acc_train: 0.8570 loss_val: 0.6224 acc_val: 0.8251 time: 0.8515s\n",
            "Epoch: 0132 loss_train: 0.4910 acc_train: 0.8460 loss_val: 0.6340 acc_val: 0.8216 time: 0.8530s\n",
            "Epoch: 0133 loss_train: 0.5054 acc_train: 0.8476 loss_val: 0.6046 acc_val: 0.8260 time: 0.8534s\n",
            "Epoch: 0134 loss_train: 0.4822 acc_train: 0.8508 loss_val: 0.6398 acc_val: 0.8277 time: 0.8531s\n",
            "Epoch: 0135 loss_train: 0.4818 acc_train: 0.8599 loss_val: 0.5981 acc_val: 0.8260 time: 0.8542s\n",
            "Epoch: 0136 loss_train: 0.4648 acc_train: 0.8625 loss_val: 0.6090 acc_val: 0.8180 time: 0.8528s\n",
            "Epoch: 0137 loss_train: 0.4893 acc_train: 0.8545 loss_val: 0.6328 acc_val: 0.8216 time: 0.8530s\n",
            "Epoch: 0138 loss_train: 0.4767 acc_train: 0.8525 loss_val: 0.6105 acc_val: 0.8233 time: 0.8516s\n",
            "Epoch: 0139 loss_train: 0.4540 acc_train: 0.8638 loss_val: 0.6007 acc_val: 0.8339 time: 0.8519s\n",
            "Epoch: 0140 loss_train: 0.4614 acc_train: 0.8593 loss_val: 0.6179 acc_val: 0.8313 time: 0.8527s\n",
            "Epoch: 0141 loss_train: 0.4703 acc_train: 0.8517 loss_val: 0.6156 acc_val: 0.8198 time: 0.8529s\n",
            "Epoch: 0142 loss_train: 0.4575 acc_train: 0.8544 loss_val: 0.6024 acc_val: 0.8251 time: 0.8525s\n",
            "Epoch: 0143 loss_train: 0.4433 acc_train: 0.8646 loss_val: 0.6070 acc_val: 0.8313 time: 0.8522s\n",
            "Epoch: 0144 loss_train: 0.4499 acc_train: 0.8621 loss_val: 0.6538 acc_val: 0.8145 time: 0.8521s\n",
            "Epoch: 0145 loss_train: 0.5038 acc_train: 0.8374 loss_val: 0.6193 acc_val: 0.8233 time: 0.8534s\n",
            "Early Stopping...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQwlWq6dyYJm"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmPNukmk40gd"
      },
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "def test():\n",
        "    model.eval()\n",
        "    output = model(features, adj)\n",
        "    predictions = torch.argmax(output[idx_test],-1).cpu().tolist()\n",
        "    acc = accuracy_score(test_labels,predictions)\n",
        "    f11 = f1_score(test_labels,predictions, average='macro')\n",
        "    f12 = f1_score(test_labels,predictions, average = 'weighted')\n",
        "    return acc, f11, f12\n",
        "\n",
        "print(test())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOFsVlv4hTgc"
      },
      "source": [
        "# Test 10 times"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydMqrCkehVPW"
      },
      "source": [
        "for t in range(10):\n",
        "    model = GCN(nfeat=node_size, nhid=HIDDEN_DIM, nclass=num_class, dropout=DROP_OUT,n_layers=NUM_LAYERS).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
        "    idx_train, idx_val, idx_test = generate_train_val()\n",
        "    train_model(show_result=False)\n",
        "    acc, f11, f12 = test()\n",
        "    test_acc_list.append(acc)\n",
        "    test_f11_list.append(f11)\n",
        "    test_f12_list.append(f12)\n",
        "\n",
        "\n",
        "print(\"Accuracy:\",np.round(np.mean(test_acc_list),4))\n",
        "print(\"Macro F1:\",np.round(np.mean(test_f11_list),4))\n",
        "print(\"Weighted F1:\",np.round(np.mean(test_f12_list),4))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}